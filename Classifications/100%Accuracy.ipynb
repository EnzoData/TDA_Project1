{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy \n",
    "from scipy import ndimage\n",
    "import PIL\n",
    "from persim import plot_diagrams\n",
    "from ripser import ripser, lower_star_img \n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping through all the letters in every direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left-to-right scanning through loops\n",
    "letters = genfromtxt('letters.csv', delimiter=',') # Upload the file\n",
    "\n",
    "dgmLR = [None]*26 #Initialize an empty list\n",
    "for i in range(26):\n",
    "    letter_one_line=letters[i,:]\n",
    "\n",
    "    # initialize matrix of size 10x10 with all values 100\n",
    "    letter=np.full((10, 10), 100)\n",
    "\n",
    "    # convert one line letter to 10x10 matrix replacing zeros with 100\n",
    "    for k in range(1,101):\n",
    "        if letter_one_line[k]==1.0:\n",
    "            row=int((k-1)/10) \n",
    "            column=(k-1)%10 \n",
    "            letter[row,column]=k%10            \n",
    "    dgmLR[i] = lower_star_img(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 2., inf]]), array([[ 3., inf]]), array([[ 2., inf]]), array([[ 3., inf]]), array([[ 3., inf]]), array([[ 3., inf]]), array([[ 2., inf]]), array([[ 3., inf]]), array([[ 4.,  5.],\n",
      "       [ 4., inf]]), array([[ 4.,  6.],\n",
      "       [ 4., inf]]), array([[ 3., inf]]), array([[ 3., inf]]), array([[ 2., inf]]), array([[ 2., inf]]), array([[ 2., inf]]), array([[ 3., inf]]), array([[ 6.,  7.],\n",
      "       [ 2., inf]]), array([[ 3., inf]]), array([[ 3.,  8.],\n",
      "       [ 3., inf]]), array([[ 2., inf]]), array([[ 3., inf]]), array([[ 2., inf]]), array([[ 2., inf]]), array([[ 3.,  4.],\n",
      "       [ 3., inf]]), array([[ 3., inf]])]\n"
     ]
    }
   ],
   "source": [
    "# Print A-Z diagrams\n",
    "print(dgmLR[0:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch process scanning-right-to-left of all letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right-to-left scanning through loops\n",
    "letters = genfromtxt('letters.csv', delimiter=',') # Upload the file\n",
    "\n",
    "dgmRL = [None]*26 #Initialize an empty list\n",
    "for i in range(26):\n",
    "    letter_one_line=letters[i,:]\n",
    "\n",
    "    # initialize matrix of size 10x10 with all values 100\n",
    "    letter=np.full((10, 10), 100)\n",
    "\n",
    "    # convert one line letter to 10x10 matrix replacing zeros with 100\n",
    "    for k in range(1,101):\n",
    "        if letter_one_line[k]==1.0:\n",
    "            row=int((k-1)/10) \n",
    "            column=(k-1)%10 \n",
    "            letter[row,column]=10-k%10            \n",
    "    dgmRL[i] = lower_star_img(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 2., inf]]), array([[ 3.,  4.],\n",
      "       [ 2., inf]]), array([[ 2.,  7.],\n",
      "       [ 2., inf]]), array([[ 1., inf]]), array([[ 2.,  7.],\n",
      "       [ 2.,  7.],\n",
      "       [ 2., inf]]), array([[ 3.,  7.],\n",
      "       [ 3., inf]]), array([[ 3.,  7.],\n",
      "       [ 3., inf]]), array([[ 3., inf]]), array([[ 4.,  5.],\n",
      "       [ 4., inf]]), array([[ 4., inf]]), array([[ 3.,  6.],\n",
      "       [ 3., inf]]), array([[ 3., inf]]), array([[ 2., inf]]), array([[ 3., inf]]), array([[ 2., inf]]), array([[ 2., inf]]), array([[ 2., inf]]), array([[ 3.,  5.],\n",
      "       [ 3., inf]]), array([[ 2.,  7.],\n",
      "       [ 2., inf]]), array([[ 2., inf]]), array([[ 2., inf]]), array([[ 2., inf]]), array([[ 1., inf]]), array([[ 3.,  5.],\n",
      "       [ 3., inf]]), array([[ 3., inf]])]\n"
     ]
    }
   ],
   "source": [
    "# Print A-Z diagrams\n",
    "print(dgmRL[0:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch process scanning-from-up-to-down of all letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Up-to-down scanning through loops\n",
    "letters = genfromtxt('letters.csv', delimiter=',') # Upload the file\n",
    "\n",
    "dgmUD = [None]*26 #Initialize an empty list\n",
    "for i in range(26):\n",
    "    letter_one_line=letters[i,:]\n",
    "\n",
    "    # initialize matrix of size 10x10 with all values 100\n",
    "    letter=np.full((10, 10), 100)\n",
    "\n",
    "    # convert one line letter to 10x10 matrix replacing zeros with 100\n",
    "    for k in range(1,101):\n",
    "        if letter_one_line[k]==1.0:\n",
    "            row=int((k-1)%10) \n",
    "            column=(k-1)/10 \n",
    "            letter[row,column]=k%10            \n",
    "    dgmUD[i] = lower_star_img(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 2., inf]]), array([[ 3., inf]]), array([[ 2., inf]]), array([[ 3., inf]]), array([[ 3., inf]]), array([[ 3., inf]]), array([[ 2., inf]]), array([[ 3., inf]]), array([[ 4.,  5.],\n",
      "       [ 4., inf]]), array([[ 4.,  6.],\n",
      "       [ 4., inf]]), array([[ 3., inf]]), array([[ 3., inf]]), array([[ 2., inf]]), array([[ 2., inf]]), array([[ 2., inf]]), array([[ 3., inf]]), array([[ 6.,  7.],\n",
      "       [ 2., inf]]), array([[ 3., inf]]), array([[ 3.,  8.],\n",
      "       [ 3., inf]]), array([[ 2., inf]]), array([[ 3., inf]]), array([[ 2., inf]]), array([[ 2., inf]]), array([[ 3.,  4.],\n",
      "       [ 3., inf]]), array([[ 3., inf]])]\n"
     ]
    }
   ],
   "source": [
    "# Print A-Z diagrams\n",
    "print(dgmUD[0:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch process scanning-from-down-to-up of all letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Up-to-down scanning through loops\n",
    "letters = genfromtxt('letters.csv', delimiter=',') # Upload the file\n",
    "\n",
    "dgmDU = [None]*26 #Initialize an empty list\n",
    "for i in range(26):\n",
    "    letter_one_line=letters[i,:]\n",
    "\n",
    "    # initialize matrix of size 10x10 with all values 100\n",
    "    letter=np.full((10, 10), 100)\n",
    "\n",
    "    # convert one line letter to 10x10 matrix replacing zeros with 100\n",
    "    for k in range(1,101):\n",
    "        if letter_one_line[k]==1.0:\n",
    "            row=int((k-1)%10) \n",
    "            column=(k-1)/10 \n",
    "            letter[row,column]=10-k%10            \n",
    "    dgmDU[i] = lower_star_img(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 2., inf]]), array([[ 3.,  4.],\n",
      "       [ 2., inf]]), array([[ 2.,  7.],\n",
      "       [ 2., inf]]), array([[ 1., inf]]), array([[ 2.,  7.],\n",
      "       [ 2.,  7.],\n",
      "       [ 2., inf]]), array([[ 3.,  7.],\n",
      "       [ 3., inf]]), array([[ 3.,  7.],\n",
      "       [ 3., inf]]), array([[ 3., inf]]), array([[ 4.,  5.],\n",
      "       [ 4., inf]]), array([[ 4., inf]]), array([[ 3.,  6.],\n",
      "       [ 3., inf]]), array([[ 3., inf]]), array([[ 2., inf]]), array([[ 3., inf]]), array([[ 2., inf]]), array([[ 2., inf]]), array([[ 2., inf]]), array([[ 3.,  5.],\n",
      "       [ 3., inf]]), array([[ 2.,  7.],\n",
      "       [ 2., inf]]), array([[ 2., inf]]), array([[ 2., inf]]), array([[ 2., inf]]), array([[ 1., inf]]), array([[ 3.,  5.],\n",
      "       [ 3., inf]]), array([[ 3., inf]])]\n"
     ]
    }
   ],
   "source": [
    "# Print A-Z diagrams\n",
    "print(dgmDU[0:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch process angle scanning-from-upper-left of all letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = genfromtxt('letters.csv', delimiter=',') # Upload the file\n",
    "\n",
    "dgmAngle = [None]*26 #Initialize an empty list\n",
    "for i in range(26):\n",
    "    letter_one_line=letters[i,:]\n",
    "\n",
    "    # initialize matrix of size 10x10 with all values 100\n",
    "    letter=np.full((10, 10), 100)\n",
    "\n",
    "    # convert one line letter to 10x10 matrix replacing zeros with 100\n",
    "    for k in range(1,101):\n",
    "        if letter_one_line[k]==1.0:\n",
    "            row=int((k-1)/10) \n",
    "            column=(k-1)%10 \n",
    "            letter[row,column]=max(k%10,int(k-1)%10)            \n",
    "    dgmAngle[i] = lower_star_img(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 2., inf]]), array([[ 3., inf]]), array([[ 2., inf]]), array([[ 3., inf]]), array([[ 3., inf]]), array([[ 3., inf]]), array([[ 2., inf]]), array([[ 3., inf]]), array([[ 4.,  5.],\n",
      "       [ 4., inf]]), array([[ 4.,  6.],\n",
      "       [ 4., inf]]), array([[ 3., inf]]), array([[ 3., inf]]), array([[ 2., inf]]), array([[ 2., inf]]), array([[ 2., inf]]), array([[ 3., inf]]), array([[ 6.,  7.],\n",
      "       [ 2., inf]]), array([[ 3., inf]]), array([[ 3.,  8.],\n",
      "       [ 3., inf]]), array([[ 2., inf]]), array([[ 3., inf]]), array([[ 2., inf]]), array([[ 2., inf]]), array([[ 3.,  4.],\n",
      "       [ 3., inf]]), array([[ 3., inf]])]\n"
     ]
    }
   ],
   "source": [
    "# Print A-Z diagrams\n",
    "print(dgmAngle[0:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch process probing scanning-from-lower-left of all letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = genfromtxt('letters.csv', delimiter=',') # Upload the file\n",
    "\n",
    "dgmDiagonal = [None]*26 #Initialize an empty list\n",
    "for i in range(26):\n",
    "    letter_one_line=letters[i,:]\n",
    "\n",
    "    # initialize matrix of size 10x10 with all values 100\n",
    "    letter=np.full((10, 10), 100)\n",
    "\n",
    "    # convert one line letter to 10x10 matrix replacing zeros with 100\n",
    "    for k in range(1,101):\n",
    "        if letter_one_line[k]==1.0:\n",
    "            row=int((k-1)/10) \n",
    "            column=(k-1)%10 \n",
    "            letter[row,column]=(column+row)*k%10            \n",
    "    dgmDiagonal[i] = lower_star_img(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.,  3.],\n",
      "       [ 0.,  4.],\n",
      "       [ 1.,  5.],\n",
      "       [ 0.,  5.],\n",
      "       [ 0., inf]]), array([[ 1.,  2.],\n",
      "       [ 0.,  4.],\n",
      "       [ 0.,  4.],\n",
      "       [ 2.,  4.],\n",
      "       [ 2.,  5.],\n",
      "       [ 0.,  6.],\n",
      "       [ 0.,  6.],\n",
      "       [ 1.,  7.],\n",
      "       [ 0., inf]]), array([[ 0.,  4.],\n",
      "       [ 1.,  5.],\n",
      "       [ 0.,  5.],\n",
      "       [ 4.,  9.],\n",
      "       [ 0., inf]]), array([[ 1.,  2.],\n",
      "       [ 0.,  4.],\n",
      "       [ 5.,  6.],\n",
      "       [ 2.,  6.],\n",
      "       [ 1.,  7.],\n",
      "       [ 0.,  8.],\n",
      "       [ 0., inf]]), array([[ 0.,  4.],\n",
      "       [ 0.,  4.],\n",
      "       [ 5.,  6.],\n",
      "       [ 1.,  7.],\n",
      "       [ 0.,  8.],\n",
      "       [ 0.,  8.],\n",
      "       [ 2.,  8.],\n",
      "       [ 4.,  9.],\n",
      "       [ 0., inf]]), array([[ 0.,  4.],\n",
      "       [ 5.,  6.],\n",
      "       [ 1.,  7.],\n",
      "       [ 0.,  8.],\n",
      "       [ 2.,  8.],\n",
      "       [ 0., inf]]), array([[ 1.,  4.],\n",
      "       [ 0.,  4.],\n",
      "       [ 0.,  5.],\n",
      "       [ 2.,  5.],\n",
      "       [ 5.,  6.],\n",
      "       [ 0., inf]]), array([[ 1.,  7.],\n",
      "       [ 2.,  8.],\n",
      "       [ 1.,  8.],\n",
      "       [ 0., inf]]), array([[ 0.,  5.],\n",
      "       [ 0.,  5.],\n",
      "       [ 0.,  5.],\n",
      "       [ 0., inf]]), array([[ 2.,  5.],\n",
      "       [ 0.,  6.],\n",
      "       [ 2.,  8.],\n",
      "       [ 0., inf]]), array([[ 1.,  2.],\n",
      "       [ 1.,  2.],\n",
      "       [ 2.,  5.],\n",
      "       [ 0.,  7.],\n",
      "       [ 2.,  8.],\n",
      "       [ 0., inf]]), array([[ 0.,  4.],\n",
      "       [ 1.,  7.],\n",
      "       [ 2.,  8.],\n",
      "       [ 0., inf]]), array([[ 0.,  2.],\n",
      "       [ 2.,  4.],\n",
      "       [ 0.,  5.],\n",
      "       [ 2.,  6.],\n",
      "       [ 2.,  8.],\n",
      "       [ 0.,  8.],\n",
      "       [ 0., inf]]), array([[ 1.,  4.],\n",
      "       [ 2.,  4.],\n",
      "       [ 0.,  5.],\n",
      "       [ 0., inf]]), array([[ 0.,  4.],\n",
      "       [ 0.,  6.],\n",
      "       [ 5.,  6.],\n",
      "       [ 2.,  6.],\n",
      "       [ 1.,  8.],\n",
      "       [ 0.,  8.],\n",
      "       [ 0., inf]]), array([[ 1.,  5.],\n",
      "       [ 5.,  6.],\n",
      "       [ 2.,  6.],\n",
      "       [ 0.,  7.],\n",
      "       [ 0., inf]]), array([[ 0.,  4.],\n",
      "       [ 0.,  6.],\n",
      "       [ 5.,  6.],\n",
      "       [ 0.,  8.],\n",
      "       [ 0.,  8.],\n",
      "       [ 2.,  8.],\n",
      "       [ 0., inf]]), array([[ 1.,  2.],\n",
      "       [ 1.,  2.],\n",
      "       [ 0.,  2.],\n",
      "       [ 2.,  4.],\n",
      "       [ 2.,  6.],\n",
      "       [ 0.,  7.],\n",
      "       [ 0., inf]]), array([[ 0.,  4.],\n",
      "       [ 2.,  5.],\n",
      "       [ 5.,  6.],\n",
      "       [ 0.,  7.],\n",
      "       [ 0.,  8.],\n",
      "       [ 2.,  8.],\n",
      "       [ 4.,  9.],\n",
      "       [ 0., inf]]), array([[ 0.,  5.],\n",
      "       [ 0.,  5.],\n",
      "       [ 0.,  5.],\n",
      "       [ 4.,  9.],\n",
      "       [ 4.,  9.],\n",
      "       [ 0., inf]]), array([[ 0.,  4.],\n",
      "       [ 1.,  7.],\n",
      "       [ 0.,  8.],\n",
      "       [ 0.,  8.],\n",
      "       [ 2.,  8.],\n",
      "       [ 0., inf]]), array([[ 0.,  2.],\n",
      "       [ 2.,  3.],\n",
      "       [ 2.,  8.],\n",
      "       [ 0., inf]]), array([[ 1.,  2.],\n",
      "       [ 0.,  2.],\n",
      "       [ 0.,  3.],\n",
      "       [ 0.,  5.],\n",
      "       [ 0.,  6.],\n",
      "       [ 5.,  6.],\n",
      "       [ 4.,  8.],\n",
      "       [ 0.,  9.],\n",
      "       [ 0., inf]]), array([[ 1.,  2.],\n",
      "       [ 0.,  2.],\n",
      "       [ 2.,  4.],\n",
      "       [ 0.,  4.],\n",
      "       [ 0., inf]]), array([[ 0.,  5.],\n",
      "       [ 0.,  8.],\n",
      "       [ 2.,  8.],\n",
      "       [ 0., inf]])]\n"
     ]
    }
   ],
   "source": [
    "# Print A-Z diagrams\n",
    "print(dgmDiagonal[0:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch process diagonal scanning-from-upper-left of all letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = genfromtxt('letters.csv', delimiter=',') # Upload the file\n",
    "\n",
    "dgmDiagonalULC = [None]*26 #Initialize an empty list\n",
    "for i in range(26):\n",
    "    letter_one_line=letters[i,:]\n",
    "\n",
    "    # initialize matrix of size 10x10 with all values 100\n",
    "    letter=np.full((10, 10), 100)\n",
    "\n",
    "    # convert one line letter to 10x10 matrix replacing zeros with 100\n",
    "    for k in range(1,101):\n",
    "        if letter_one_line[k]==1.0:\n",
    "            row=int((k-1)/10) \n",
    "            column=(k-1)%10 \n",
    "            letter[row,column]=k%10 + int((k-1)/10)            \n",
    "    dgmDiagonalULC[i] = lower_star_img(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 5., inf]]), array([[ 3., inf]]), array([[ 5., inf]]), array([[ 4., inf]]), array([[ 4., inf]]), array([[ 4., inf]]), array([[ 4., inf]]), array([[ 8.,  9.],\n",
      "       [ 4., inf]]), array([[ 5., inf]]), array([[11., 12.],\n",
      "       [ 5., inf]]), array([[ 4., inf]]), array([[ 4., inf]]), array([[ 8.,  9.],\n",
      "       [ 3., inf]]), array([[ 8., 11.],\n",
      "       [ 3., inf]]), array([[ 4., inf]]), array([[ 4., inf]]), array([[12., 14.],\n",
      "       [ 4., inf]]), array([[ 4., inf]]), array([[11., 15.],\n",
      "       [ 4., inf]]), array([[ 3., inf]]), array([[ 9., 15.],\n",
      "       [ 4., inf]]), array([[ 9., 11.],\n",
      "       [ 3., inf]]), array([[ 7.,  9.],\n",
      "       [10., 13.],\n",
      "       [ 3., inf]]), array([[ 8.,  9.],\n",
      "       [ 4., inf]]), array([[ 8., 10.],\n",
      "       [ 4., inf]])]\n"
     ]
    }
   ],
   "source": [
    "# Print A-Z diagrams\n",
    "print(dgmDiagonalULC[0:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch process probing scanning-from-lower-left of all letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = genfromtxt('letters.csv', delimiter=',') # Upload the file\n",
    "\n",
    "dgmAngleLF = [None]*26 #Initialize an empty list\n",
    "for i in range(26):\n",
    "    letter_one_line=letters[i,:]\n",
    "\n",
    "    # initialize matrix of size 10x10 with all values 100\n",
    "    letter=np.full((10, 10), 100)\n",
    "\n",
    "    # convert one line letter to 10x10 matrix replacing zeros with 100\n",
    "    for k in range(1,101):\n",
    "        if letter_one_line[k]==1.0:\n",
    "            row=int((k-1)/10) \n",
    "            column=(k-1)%10 \n",
    "            letter[row,column]=max(9-(k-1)%10,9-int((k-1)/10))             \n",
    "    dgmAngleLF[i] = lower_star_img(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 2., inf]]), array([[ 2., inf]]), array([[ 2., inf]]), array([[ 2., inf]]), array([[ 5.,  7.],\n",
      "       [ 2., inf]]), array([[ 5., inf]]), array([[ 3., inf]]), array([[ 3., inf]]), array([[ 4., inf]]), array([[ 4., inf]]), array([[ 3., inf]]), array([[ 3., inf]]), array([[ 5.,  7.],\n",
      "       [ 2., inf]]), array([[ 3., inf]]), array([[ 7.,  8.],\n",
      "       [ 2., inf]]), array([[ 4., inf]]), array([[ 7.,  8.],\n",
      "       [ 2., inf]]), array([[ 3., inf]]), array([[ 2., inf]]), array([[ 5., inf]]), array([[ 2., inf]]), array([[ 4., inf]]), array([[ 5.,  6.],\n",
      "       [ 2., inf]]), array([[ 3., inf]]), array([[ 4., inf]])]\n"
     ]
    }
   ],
   "source": [
    "# Print A-Z diagrams\n",
    "print(dgmAngleLF[0:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bottle Neck Distance Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 1, 1, 1, 2, 1, 0, 0, 1, 1, 2, 2, 2, 1, 2, 1, 3, 2, 1, 2,\n",
       "       2, 1, 1, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the persim package and run the test in every direction left-to-right\n",
    "import persim as pm\n",
    "\n",
    "# Set an empty pairwise distance matrix for future bottleneck distance input\n",
    "BNDLR = np.zeros((26,26))\n",
    "\n",
    "\n",
    "# Change infinities to very large numbers\n",
    "for i in range(26):\n",
    "    dgmLR[i][np.isinf(dgmLR[i])] = 10000\n",
    "\n",
    "# Calculate bottleneck distances and input into the pairwise matrix\n",
    "for i in range(26):\n",
    "    for j in range(26):\n",
    "        BNDLR[i,j] = pm.bottleneck(dgmLR[i], dgmLR[j])\n",
    "\n",
    "# The very large values should be set to 0 by bottleneck definity (since the very large distances would be inifinity)\n",
    "BNDLR[BNDLR>1000]=0\n",
    "\n",
    "# Now we look to perform clustering on this pairwise distance matrix. For simplicity we use sklearn's Agglomerative Clustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# For now we set 3 clusters, but we can change this and look for better results in our model. A lower number here will prevent overfitting.\n",
    "clusteringLR = AgglomerativeClustering(n_clusters = 5,\n",
    "                                     affinity = \"precomputed\",\n",
    "                                     linkage = \"average\").fit(BNDLR)\n",
    "\n",
    "# This will output a vector of length 26 representing a number for each letter for this scan.\n",
    "LR_test = clusteringLR.labels_\n",
    "LR_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0, 3, 2, 2, 4, 1, 1, 2, 4, 0, 4, 0, 0, 0, 1, 2, 0, 0, 0,\n",
       "       0, 1, 4, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the persim package and run the test in every direction right-to-left\n",
    "import persim as pm\n",
    "\n",
    "# Set an empty pairwise distance matrix for future bottleneck distance input\n",
    "BNDRL = np.zeros((26,26))\n",
    "\n",
    "\n",
    "# Change infinities to very large numbers\n",
    "for i in range(26):\n",
    "    dgmRL[i][np.isinf(dgmRL[i])] = 10000\n",
    "\n",
    "# Calculate bottleneck distances and input into the pairwise matrix\n",
    "for i in range(26):\n",
    "    for j in range(26):\n",
    "        BNDRL[i,j] = pm.bottleneck(dgmRL[i], dgmRL[j])\n",
    "\n",
    "# The very large values should be set to 0 by bottleneck definity (since the very large distances would be inifinity)\n",
    "BNDRL[BNDRL>1000]=0\n",
    "\n",
    "# Now we look to perform clustering on this pairwise distance matrix. For simplicity we use sklearn's Agglomerative Clustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# For now we set 3 clusters, but we can change this and look for better results in our model. A lower number here will prevent overfitting.\n",
    "clusteringRL = AgglomerativeClustering(n_clusters = 5,\n",
    "                                     affinity = \"precomputed\",\n",
    "                                     linkage = \"average\").fit(BNDRL)\n",
    "\n",
    "# This will output a vector of length 26 representing a number for each letter for this scan.\n",
    "RL_test = clusteringRL.labels_\n",
    "RL_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0, 3, 2, 2, 4, 1, 1, 2, 4, 0, 4, 0, 0, 0, 1, 2, 0, 0, 0,\n",
       "       0, 1, 4, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the persim package and run the test in every direction down-to-up\n",
    "import persim as pm\n",
    "\n",
    "# Set an empty pairwise distance matrix for future bottleneck distance input\n",
    "BNDDU = np.zeros((26,26))\n",
    "\n",
    "\n",
    "# Change infinities to very large numbers\n",
    "for i in range(26):\n",
    "    dgmDU[i][np.isinf(dgmDU[i])] = 10000\n",
    "\n",
    "# Calculate bottleneck distances and input into the pairwise matrix\n",
    "for i in range(26):\n",
    "    for j in range(26):\n",
    "        BNDDU[i,j] = pm.bottleneck(dgmDU[i], dgmDU[j])\n",
    "\n",
    "# The very large values should be set to 0 by bottleneck definity (since the very large distances would be inifinity)\n",
    "BNDDU[BNDDU>1000]=0\n",
    "\n",
    "# Now we look to perform clustering on this pairwise distance matrix. For simplicity we use sklearn's Agglomerative Clustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# For now we set 3 clusters, but we can change this and look for better results in our model. A lower number here will prevent overfitting.\n",
    "clusteringDU = AgglomerativeClustering(n_clusters = 5,\n",
    "                                     affinity = \"precomputed\",\n",
    "                                     linkage = \"average\").fit(BNDDU)\n",
    "\n",
    "# This will output a vector of length 26 representing a number for each letter for this scan.\n",
    "DU_test = clusteringDU.labels_\n",
    "DU_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 1, 1, 1, 2, 1, 0, 0, 1, 1, 2, 2, 2, 1, 2, 1, 3, 2, 1, 2,\n",
       "       2, 1, 1, 4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the persim package and run the test in every direction up-to-down\n",
    "import persim as pm\n",
    "\n",
    "# Set an empty pairwise distance matrix for future bottleneck distance input\n",
    "BNDUD = np.zeros((26,26))\n",
    "\n",
    "\n",
    "# Change infinities to very large numbers\n",
    "for i in range(26):\n",
    "    dgmUD[i][np.isinf(dgmUD[i])] = 10000\n",
    "\n",
    "# Calculate bottleneck distances and input into the pairwise matrix\n",
    "for i in range(26):\n",
    "    for j in range(26):\n",
    "        BNDUD[i,j] = pm.bottleneck(dgmUD[i], dgmUD[j])\n",
    "\n",
    "# The very large values should be set to 0 by bottleneck definity (since the very large distances would be inifinity)\n",
    "BNDUD[BNDUD>1000]=0\n",
    "\n",
    "# Now we look to perform clustering on this pairwise distance matrix. For simplicity we use sklearn's Agglomerative Clustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# For now we set 3 clusters, but we can change this and look for better results in our model. A lower number here will prevent overfitting.\n",
    "clusteringUD = AgglomerativeClustering(n_clusters = 5,\n",
    "                                     affinity = \"precomputed\",\n",
    "                                     linkage = \"average\").fit(BNDUD)\n",
    "\n",
    "# This will output a vector of length 26 representing a number for each letter for this scan.\n",
    "UD_test = clusteringUD.labels_\n",
    "UD_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 1, 1, 1, 2, 1, 0, 0, 1, 1, 2, 2, 2, 1, 2, 1, 3, 2, 1, 2,\n",
       "       2, 1, 1, 4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the persim package and run the test in every direction angle from-upper-left\n",
    "import persim as pm\n",
    "\n",
    "# Set an empty pairwise distance matrix for future bottleneck distance input\n",
    "BNDAngle = np.zeros((26,26))\n",
    "\n",
    "\n",
    "# Change infinities to very large numbers\n",
    "for i in range(26):\n",
    "    dgmAngle[i][np.isinf(dgmAngle[i])] = 10000\n",
    "\n",
    "# Calculate bottleneck distances and input into the pairwise matrix\n",
    "for i in range(26):\n",
    "    for j in range(26):\n",
    "        BNDAngle[i,j] = pm.bottleneck(dgmAngle[i], dgmAngle[j])\n",
    "\n",
    "# The very large values should be set to 0 by bottleneck definity (since the very large distances would be inifinity)\n",
    "BNDAngle[BNDAngle>1000]=0\n",
    "\n",
    "# Now we look to perform clustering on this pairwise distance matrix. For simplicity we use sklearn's Agglomerative Clustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# For now we set 3 clusters, but we can change this and look for better results in our model. A lower number here will prevent overfitting.\n",
    "clusteringAngle = AgglomerativeClustering(n_clusters = 5,\n",
    "                                     affinity = \"precomputed\",\n",
    "                                     linkage = \"average\").fit(BNDAngle)\n",
    "\n",
    "# This will output a vector of length 26 representing a number for each letter for this scan.\n",
    "A_test = clusteringAngle.labels_\n",
    "A_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 0, 1, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 1, 0, 1, 4, 1, 3,\n",
       "       0, 2, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the persim package and run the test in every diagonally from-lower-left\n",
    "import persim as pm\n",
    "\n",
    "# Set an empty pairwise distance matrix for future bottleneck distance input\n",
    "BNDDiagonal = np.zeros((26,26))\n",
    "\n",
    "\n",
    "# Change infinities to very large numbers\n",
    "for i in range(26):\n",
    "    dgmDiagonal[i][np.isinf(dgmDiagonal[i])] = 10000\n",
    "\n",
    "# Calculate bottleneck distances and input into the pairwise matrix\n",
    "for i in range(26):\n",
    "    for j in range(26):\n",
    "        BNDDiagonal[i,j] = pm.bottleneck(dgmDiagonal[i], dgmDiagonal[j])\n",
    "\n",
    "# The very large values should be set to 0 by bottleneck definity (since the very large distances would be inifinity)\n",
    "BNDDiagonal[BNDDiagonal>1000]=0\n",
    "\n",
    "# Now we look to perform clustering on this pairwise distance matrix. For simplicity we use sklearn's Agglomerative Clustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# For now we set 3 clusters, but we can change this and look for better results in our model. A lower number here will prevent overfitting.\n",
    "clusteringDiagonal = AgglomerativeClustering(n_clusters = 5,\n",
    "                                     affinity = \"precomputed\",\n",
    "                                     linkage = \"average\").fit(BNDDiagonal)\n",
    "\n",
    "# This will output a vector of length 26 representing a number for each letter for this scan.\n",
    "D_test = clusteringDiagonal.labels_\n",
    "D_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 3, 1,\n",
       "       4, 0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the persim package and run the test in every direction left-to-right\n",
    "import persim as pm\n",
    "\n",
    "# Set an empty pairwise distance matrix for future bottleneck distance input\n",
    "BNDULC = np.zeros((26,26))\n",
    "\n",
    "\n",
    "# Change infinities to very large numbers\n",
    "for i in range(26):\n",
    "    dgmDiagonalULC[i][np.isinf(dgmDiagonalULC[i])] = 10000\n",
    "\n",
    "# Calculate bottleneck distances and input into the pairwise matrix\n",
    "for i in range(26):\n",
    "    for j in range(26):\n",
    "        BNDULC[i,j] = pm.bottleneck(dgmDiagonalULC[i], dgmDiagonalULC[j])\n",
    "\n",
    "# The very large values should be set to 0 by bottleneck definity (since the very large distances would be inifinity)\n",
    "BNDULC[BNDULC>1000]=0\n",
    "\n",
    "# Now we look to perform clustering on this pairwise distance matrix. For simplicity we use sklearn's Agglomerative Clustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# For now we set 3 clusters, but we can change this and look for better results in our model. A lower number here will prevent overfitting.\n",
    "clusteringULC = AgglomerativeClustering(n_clusters = 5,\n",
    "                                     affinity = \"precomputed\",\n",
    "                                     linkage = \"average\").fit(BNDULC)\n",
    "\n",
    "# This will output a vector of length 26 representing a number for each letter for this scan.\n",
    "ULC_test = clusteringULC.labels_\n",
    "ULC_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 3, 1,\n",
       "       4, 0, 0, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the persim package and run the test in every direction left-to-right\n",
    "import persim as pm\n",
    "\n",
    "# Set an empty pairwise distance matrix for future bottleneck distance input\n",
    "BNDALF = np.zeros((26,26))\n",
    "\n",
    "\n",
    "# Change infinities to very large numbers\n",
    "for i in range(26):\n",
    "    dgmAngleLF[i][np.isinf(dgmAngleLF[i])] = 10000\n",
    "\n",
    "# Calculate bottleneck distances and input into the pairwise matrix\n",
    "for i in range(26):\n",
    "    for j in range(26):\n",
    "        BNDALF[i,j] = pm.bottleneck(dgmAngleLF[i], dgmAngleLF[j])\n",
    "\n",
    "# The very large values should be set to 0 by bottleneck definity (since the very large distances would be inifinity)\n",
    "BNDALF[BNDALF>1000]=0\n",
    "\n",
    "# Now we look to perform clustering on this pairwise distance matrix. For simplicity we use sklearn's Agglomerative Clustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# For now we set 3 clusters, but we can change this and look for better results in our model. A lower number here will prevent overfitting.\n",
    "clusteringALF = AgglomerativeClustering(n_clusters = 5,\n",
    "                                     affinity = \"precomputed\",\n",
    "                                     linkage = \"average\").fit(BNDULC)\n",
    "\n",
    "# This will output a vector of length 26 representing a number for each letter for this scan.\n",
    "ALF_test = clusteringALF.labels_\n",
    "ALF_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 1, 1, 1, 2, 1, 0, 0, 1, 1, 2, 2, 2, 1, 2, 1, 3, 2, 1, 2,\n",
       "       2, 1, 1, 4, 0, 0, 2, 0, 3, 2, 2, 4, 1, 1, 2, 4, 0, 4, 0, 0, 0, 1,\n",
       "       2, 0, 0, 0, 0, 1, 4, 2, 0, 0, 2, 0, 3, 2, 2, 4, 1, 1, 2, 4, 0, 4,\n",
       "       0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 4, 2, 2, 1, 2, 1, 1, 1, 2, 1, 0, 0,\n",
       "       1, 1, 2, 2, 2, 1, 2, 1, 3, 2, 1, 2, 2, 1, 1, 4, 2, 1, 2, 1, 1, 1,\n",
       "       2, 1, 0, 0, 1, 1, 2, 2, 2, 1, 2, 1, 3, 2, 1, 2, 2, 1, 1, 4, 2, 0,\n",
       "       0, 0, 1, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 1, 0, 1, 4, 1, 3, 0, 2,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0,\n",
       "       3, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 2, 0, 3, 1, 4, 0, 0, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array = np.concatenate((LR_test, RL_test, DU_test, UD_test, A_test, D_test, ULC_test, ALF_test))\n",
    "test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array = np.reshape(test_array,(8,26)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 2, 2, 2, 0, 0],\n",
       "       [1, 0, 0, 1, 1, 0, 0, 0],\n",
       "       [2, 2, 2, 2, 2, 0, 0, 0],\n",
       "       [1, 0, 0, 1, 1, 0, 0, 0],\n",
       "       [1, 3, 3, 1, 1, 1, 0, 0],\n",
       "       [1, 2, 2, 1, 1, 0, 0, 0],\n",
       "       [2, 2, 2, 2, 2, 2, 0, 0],\n",
       "       [1, 4, 4, 1, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 2, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 2, 2, 1, 1, 0, 0, 0],\n",
       "       [1, 4, 4, 1, 1, 0, 0, 0],\n",
       "       [2, 0, 0, 2, 2, 0, 0, 0],\n",
       "       [2, 4, 4, 2, 2, 2, 1, 1],\n",
       "       [2, 0, 0, 2, 2, 0, 0, 0],\n",
       "       [1, 0, 0, 1, 1, 0, 0, 0],\n",
       "       [2, 0, 0, 2, 2, 1, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 0, 0, 0],\n",
       "       [3, 2, 2, 3, 3, 1, 2, 2],\n",
       "       [2, 0, 0, 2, 2, 4, 0, 0],\n",
       "       [1, 0, 0, 1, 1, 1, 3, 3],\n",
       "       [2, 0, 0, 2, 2, 3, 1, 1],\n",
       "       [2, 0, 0, 2, 2, 0, 4, 4],\n",
       "       [1, 1, 1, 1, 1, 2, 0, 0],\n",
       "       [1, 4, 4, 1, 1, 0, 0, 0],\n",
       "       [4, 2, 2, 4, 4, 0, 0, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same Distances appear\n",
    "From the test_array we can see that there are multiple like terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 2, 2, 0, 0, 0],\n",
       "       [1, 0, 0, 1, 1, 0, 0, 0],\n",
       "       [2, 0, 0, 2, 2, 1, 0, 0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array[14:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 1, 1, 1, 2, 1, 0, 0, 1, 1, 2, 2, 2, 1, 2, 1, 3, 2, 1, 2,\n",
       "       2, 1, 1, 4])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 1, 1, 1, 2, 1, 0, 0, 1, 1, 2, 2, 2, 1, 2, 1, 3, 2, 1, 2,\n",
       "       2, 1, 1, 4])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0, 3, 2, 2, 4, 1, 1, 2, 4, 0, 4, 0, 0, 0, 1, 2, 0, 0, 0,\n",
       "       0, 1, 4, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0, 3, 2, 2, 4, 1, 1, 2, 4, 0, 4, 0, 0, 0, 1, 2, 0, 0, 0,\n",
       "       0, 1, 4, 2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RL_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0, 3, 2, 2, 4, 1, 1, 2, 4, 0, 4, 0, 0, 0, 1, 2, 0, 0, 0,\n",
       "       0, 1, 4, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 1, 1, 1, 2, 1, 0, 0, 1, 1, 2, 2, 2, 1, 2, 1, 3, 2, 1, 2,\n",
       "       2, 1, 1, 4])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UD_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 1, 1, 1, 2, 1, 0, 0, 1, 1, 2, 2, 2, 1, 2, 1, 3, 2, 1, 2,\n",
       "       2, 1, 1, 4])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0, 3, 2, 2, 4, 1, 1, 2, 4, 0, 4, 0, 0, 0, 1, 2, 0, 0, 0,\n",
       "       0, 1, 4, 2])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DU_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 1, 1, 1, 2, 1, 0, 0, 1, 1, 2, 2, 2, 1, 2, 1, 3, 2, 1, 2,\n",
       "       2, 1, 1, 4])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 0, 1, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 1, 0, 1, 4, 1, 3,\n",
       "       0, 2, 0, 0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 0, 1, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 1, 0, 1, 4, 1, 3,\n",
       "       0, 2, 0, 0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 3, 1,\n",
       "       4, 0, 0, 0])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ULC_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 1, 1, 1, 2, 1, 0, 0, 1, 1, 2, 2, 2, 1, 2, 1, 3, 2, 1, 2,\n",
       "       2, 1, 1, 4])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 3, 1,\n",
       "       4, 0, 0, 0])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALF_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observing linear dipendencies\n",
    "#### LR, DU, Angle\n",
    "#### RL, UD all have similar characteristics\n",
    "#### Diagonal scanning provided unique characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A test to differentiate some letters\n",
    "bottom_test = [None]*26\n",
    "for i in range(26):\n",
    "    bottom_test[i]=sum(letters[i][51:101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_test = [None]*26  \n",
    "for i in range(26):\n",
    "    right_test[i]=sum(np.concatenate((letters[i][6:11],\n",
    "              letters[i][16:21],\n",
    "              letters[i][26:31],\n",
    "              letters[i][36:41],\n",
    "              letters[i][46:51],\n",
    "              letters[i][56:61],\n",
    "              letters[i][66:71],\n",
    "              letters[i][76:81],\n",
    "              letters[i][86:91],\n",
    "              letters[i][96:101]\n",
    "              )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "botright = [None]*26\n",
    "for i in range(26):\n",
    "    botright[i] = sum(np.concatenate((\n",
    "              letters[i][56:61],\n",
    "              letters[i][66:71],\n",
    "              letters[i][76:81],\n",
    "              letters[i][86:91],\n",
    "              letters[i][96:101]\n",
    "              )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_test = [None]*26\n",
    "for i in range(26):\n",
    "    top_test[i] = sum(letters[i][1:51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_test = [None]*26\n",
    "for i in range(26):\n",
    "    density_test[i] = sum(letters[i][1:101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us combine our vectors into a workable array\n",
    "test_array = np.concatenate((LR_test,\n",
    "                             RL_test,\n",
    "                             A_test,\n",
    "                             D_test,\n",
    "                             bottom_test,\n",
    "                             right_test,\n",
    "                             botright,\n",
    "                             top_test,\n",
    "                             density_test))\n",
    "test_array = np.reshape(test_array,(9,26)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab our labels\n",
    "training_labels = [None]*26\n",
    "for i in range(26):\n",
    "    training_labels[i] = letters[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enzo/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/enzo/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "       14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit our model and see if it has 100% accuracy on training data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LogReg=LogisticRegression()\n",
    "LogReg.fit(test_array, training_labels)\n",
    "y_pred = LogReg.predict(test_array)\n",
    "y_pred\n",
    "# It does! 100% accuracy. Next step is to create function that will take a new letter input and output the prediction using this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
